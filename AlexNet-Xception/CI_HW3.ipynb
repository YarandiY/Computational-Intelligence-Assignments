{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CI_HW3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ux3Pp-sQXETP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc89e0c5-a665-4809-907f-ab1befe8d7c8"
      },
      "source": [
        "!wget http://vision.stanford.edu/aditya86/ImageNetDogs/images.tar\r\n",
        "# !wget http://files.heuritech.com/weights/alexnet_weights.h5\r\n",
        "!tar -xf images.tar"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-12-11 20:24:33--  http://vision.stanford.edu/aditya86/ImageNetDogs/images.tar\n",
            "Resolving vision.stanford.edu (vision.stanford.edu)... 171.64.68.10\n",
            "Connecting to vision.stanford.edu (vision.stanford.edu)|171.64.68.10|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 793579520 (757M) [application/x-tar]\n",
            "Saving to: ‘images.tar’\n",
            "\n",
            "images.tar          100%[===================>] 756.82M  20.3MB/s    in 40s     \n",
            "\n",
            "2020-12-11 20:25:13 (18.9 MB/s) - ‘images.tar’ saved [793579520/793579520]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "87T5BetZQYQv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "420ba571-461f-49ea-ff84-df6d7b5fd5bb"
      },
      "source": [
        "# dataset ##################################\n",
        "import os\n",
        "from tensorflow import keras\n",
        "import tensorflow as tf\n",
        "assert tf.__version__.startswith('2')\n",
        "from tensorflow.keras.layers.experimental.preprocessing import Rescaling\n",
        "from tensorflow.keras.layers import *\n",
        "tf.random.set_seed(1234)\n",
        "!pip3 install tensorflow-datasets==1.2.0\n",
        "import tensorflow_datasets as tfds\n",
        "from matplotlib import pyplot as plt\n",
        "import cv2 as cv\n",
        "import numpy as np\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "import os\n",
        "from keras.utils.data_utils import get_file\n",
        " \n",
        "%matplotlib inline\n",
        "%load_ext tensorboard\n",
        "\n",
        "\n",
        "breeds = os.listdir(\"Images\")\n",
        "\n",
        "def get_breed_name(category):\n",
        "  breed = breeds[np.where(category == 1)[0][0]]\n",
        "  return breed.rsplit('-')[1]\n",
        "\n",
        "def get_label_name(label):\n",
        "  return get_breed_name(label.numpy())\n",
        "\n",
        "def show_image(image):\n",
        "  plt.imshow(image.numpy().astype(\"uint8\"))\n",
        "  plt.show()\n",
        "\n",
        "# images_path = 'Images/'\n",
        "images_path = Path(\"Images\")\n",
        "batch_size = 32\n",
        "\n",
        "split_train, split_valid, split_test = 'train[:70%]', 'train[70%:]', 'test'\n",
        "\n",
        "\n",
        "for folder in images_path.glob(\"*\"):\n",
        "  breed = str(folder).split(\"/\")[1]\n",
        "  os.rename(folder,os.path.join(images_path,breed))\n",
        "\n",
        "np.random.seed(28)\n",
        "\n",
        "if os.path.exists(\"./dataset\"):\n",
        "    shutil.rmtree(\"./dataset\")\n",
        "train_path = Path(\"./dataset/train\")\n",
        "test_path = Path(\"./dataset/test\")\n",
        "\n",
        "os.makedirs(train_path,exist_ok=True)\n",
        "os.makedirs(test_path,exist_ok=True)\n",
        "\n",
        "test_split=0.05\n",
        "total_test_size=0\n",
        "total_train_size=0\n",
        "\n",
        "for breed_folder in images_path.glob(\"*\"):\n",
        "\n",
        "    breed = str(breed_folder).split(\"/\")[-1]\n",
        "    imgs = np.array(list(breed_folder.glob(\"*.jpg\")))\n",
        "    indices = np.random.permutation(len(imgs))\n",
        "\n",
        "    test_size=int(len(imgs)*test_split)\n",
        "    \n",
        "    test_ds=imgs[indices[:test_size]]\n",
        "    train_ds=imgs[indices[test_size:]]\n",
        "\n",
        "    total_test_size += len(test_ds)\n",
        "    total_train_size += len(train_ds)\n",
        "\n",
        "    os.makedirs(os.path.join(train_path,breed),exist_ok=True)\n",
        "    os.makedirs(os.path.join(test_path,breed),exist_ok=True)\n",
        "\n",
        "    for im in test_ds:\n",
        "        filename = f\"{im.stem}.jpg\"\n",
        "        shutil.copy(im,os.path.join(test_path,breed,filename))\n",
        "\n",
        "    for im in train_ds:\n",
        "        filename = f\"{im.stem}.jpg\"\n",
        "        shutil.copy(im,os.path.join(train_path,breed,filename)) \n",
        "\n",
        "\n",
        "print(f\"train size: {total_train_size}\")\n",
        "print(f\"test size: {total_test_size}\")\n",
        "\n",
        "\n",
        "def load_images():\n",
        "  train_ds = keras.preprocessing.image_dataset_from_directory(train_path,\n",
        "                                                                validation_split=0.2,\n",
        "                                                                subset=\"training\",\n",
        "                                                                seed=28,\n",
        "                                                                shuffle=True,\n",
        "                                                                image_size=(227, 227),\n",
        "                                                                batch_size=batch_size,\n",
        "                                                                label_mode='categorical')\n",
        "  valid_ds = keras.preprocessing.image_dataset_from_directory(train_path,\n",
        "                                                                validation_split=0.2,\n",
        "                                                                subset=\"validation\",\n",
        "                                                                seed=28,\n",
        "                                                                image_size=(227, 227),\n",
        "                                                                batch_size=batch_size,\n",
        "                                                                label_mode='categorical')\n",
        "  test_ds = keras.preprocessing.image_dataset_from_directory(test_path,\n",
        "                                                                seed=28,\n",
        "                                                                batch_size=batch_size,\n",
        "                                                                image_size=(227, 227),\n",
        "                                                                label_mode='categorical')\n",
        "  train_ds = train_ds.prefetch(buffer_size=32)\n",
        "  valid_ds = valid_ds.prefetch(buffer_size=32)\n",
        "  return train_ds, valid_ds, test_ds\n",
        "\n",
        "# def load_images():\n",
        "  # train_ds = keras.preprocessing.image_dataset_from_directory(\n",
        "  # 'Images/',\n",
        "  # validation_split=0.2,\n",
        "  # subset=\"training\",\n",
        "  # seed=123,\n",
        "  # image_size=(227, 227),\n",
        "  # batch_size=32,\n",
        "  # shuffle=True,\n",
        "  # label_mode='categorical'\n",
        "  # )\n",
        "  # val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "  # 'Images/',\n",
        "  # validation_split=0.2,\n",
        "  # subset=\"validation\",\n",
        "  # seed=123,\n",
        "  # image_size=(227, 227),\n",
        "  # batch_size=32,\n",
        "  # shuffle=True,\n",
        "  # label_mode='categorical')\n",
        "  # return train_ds, val_ds\n",
        "\n",
        "train_ds, val_ds, test_ds = load_images()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow-datasets==1.2.0 in /usr/local/lib/python3.6/dist-packages (1.2.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets==1.2.0) (0.16.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets==1.2.0) (0.10.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets==1.2.0) (1.18.5)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets==1.2.0) (0.25.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets==1.2.0) (4.41.1)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets==1.2.0) (0.3.3)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets==1.2.0) (1.1.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets==1.2.0) (5.4.8)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets==1.2.0) (2.3)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets==1.2.0) (20.3.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets==1.2.0) (2.23.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets==1.2.0) (3.12.4)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets==1.2.0) (1.12.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets==1.2.0) (1.15.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-metadata->tensorflow-datasets==1.2.0) (1.52.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->tensorflow-datasets==1.2.0) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->tensorflow-datasets==1.2.0) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->tensorflow-datasets==1.2.0) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->tensorflow-datasets==1.2.0) (2020.12.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow-datasets==1.2.0) (50.3.2)\n",
            "train size: 19619\n",
            "test size: 961\n",
            "Found 19619 files belonging to 120 classes.\n",
            "Using 15696 files for training.\n",
            "Found 19619 files belonging to 120 classes.\n",
            "Using 3923 files for validation.\n",
            "Found 961 files belonging to 120 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nMrExU_pXJHf"
      },
      "source": [
        "# preprocessing ##################\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "\r\n",
        "def normalization(images):\r\n",
        "  # print(np.array(images).sum)\r\n",
        "  return (images / 255) - 0.5\r\n",
        "\r\n",
        "\r\n",
        "# augmentation ##################  \r\n",
        "\r\n",
        "# test ##########################\r\n",
        "# image, label ="
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FdlnU5j_XQ-t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "112625d2-001e-4558-b85d-c16a21d8c503"
      },
      "source": [
        "# CNN ##################################\r\n",
        "from keras.layers.normalization import BatchNormalization\r\n",
        "from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\r\n",
        "from keras.models import Sequential\r\n",
        "import keras.layers as layers\r\n",
        "from keras.utils.vis_utils import plot_model\r\n",
        "\r\n",
        "data_augmentation = keras.Sequential(\r\n",
        "  [\r\n",
        "    layers.experimental.preprocessing.RandomRotation(0.2),\r\n",
        "    layers.experimental.preprocessing.RandomZoom((0.1, 0.2), (0.1, 0.2)),\r\n",
        "  ]\r\n",
        ")\r\n",
        "\r\n",
        "def alexNet(weights=None):\r\n",
        "    model = Sequential()\r\n",
        "    \r\n",
        "    model.add(layers.Input(shape=(227, 227, 3)))\r\n",
        "    model.add(data_augmentation)\r\n",
        "\r\n",
        "    # 1 --> CONV\r\n",
        "    model.add(Conv2D(filters=96, kernel_initializer='random_normal', kernel_size=(11, 11), strides=(4, 4), padding=\"valid\", activation=\"relu\"))\r\n",
        "    # 1 --> POOLING (max pooling)\r\n",
        "    model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\r\n",
        "    model.add(BatchNormalization())\r\n",
        "\r\n",
        "    # 2 --> CONV\r\n",
        "    model.add(Conv2D(filters=256, kernel_size=(5, 5), strides=(1, 1), padding=\"valid\", activation=\"relu\"))\r\n",
        "    # 2 --> POOLING (max pooling)\r\n",
        "    model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\r\n",
        "    model.add(BatchNormalization())\r\n",
        "\r\n",
        "    # 3 --> CONV\r\n",
        "    model.add(Conv2D(filters=384, kernel_size=(3, 3), strides=(1, 1), padding=\"valid\", activation=\"relu\"))\r\n",
        "\r\n",
        "    # 4 --> CONV\r\n",
        "    model.add(Conv2D(filters=384, kernel_size=(3, 3), strides=(1, 1), padding=\"valid\", activation=\"relu\"))\r\n",
        "\r\n",
        "    # 5 --> CONV\r\n",
        "    model.add(Conv2D(filters=256, kernel_size=(3, 3), strides=(1, 1), padding=\"valid\", activation=\"relu\"))\r\n",
        "    # 5 --> POOLING (max pooling)\r\n",
        "    model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\r\n",
        "    model.add(BatchNormalization())\r\n",
        "\r\n",
        "    model.add(Flatten())\r\n",
        "\r\n",
        "    if weights is not None:\r\n",
        "\t\t   model.load_weights(weights)\r\n",
        "\r\n",
        "    # 6 --> FULLY CONNECTED\r\n",
        "    model.add(Dense(4096, input_shape=(227, 227, 3), activation=\"relu\"))\r\n",
        "    model.add(Dropout(0.5))\r\n",
        "    model.add(BatchNormalization())\r\n",
        "\r\n",
        "    # 7 --> FULLY CONNECTED\r\n",
        "    model.add(Dense(4096, activation=\"relu\"))\r\n",
        "    model.add(Dropout(0.5))\r\n",
        "    model.add(BatchNormalization())\r\n",
        "\r\n",
        "    # 7 --> FULLY CONNECTED\r\n",
        "    model.add(Dense(1000, activation=\"relu\"))\r\n",
        "    model.add(Dropout(0.5))\r\n",
        "    model.add(BatchNormalization())\r\n",
        "\r\n",
        "    # 8--> FULLY CONNECTED\r\n",
        "    model.add(Dense(1000, activation=\"relu\"))\r\n",
        "    model.add(Dropout(0.5))\r\n",
        "    model.add(BatchNormalization())\r\n",
        "\r\n",
        "    model.add(Dense(len(breeds), activation=\"softmax\"))\r\n",
        "\r\n",
        "    model.compile(optimizer='adam', loss=keras.losses.CategoricalCrossentropy(from_logits=False), metrics=[\"accuracy\"])\r\n",
        "    model.summary()\r\n",
        "    plot_model(model, to_file='model.png', show_shapes=True, show_layer_names=True)\r\n",
        "    # plt.imshow(\"model.png\")\r\n",
        "    return model\r\n",
        "\r\n",
        "model = alexNet()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "sequential (Sequential)      (None, 227, 227, 3)       0         \n",
            "_________________________________________________________________\n",
            "conv2d (Conv2D)              (None, 55, 55, 96)        34944     \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 27, 27, 96)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 27, 27, 96)        384       \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 23, 23, 256)       614656    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 11, 11, 256)       0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 11, 11, 256)       1024      \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 9, 9, 384)         885120    \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 7, 7, 384)         1327488   \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 5, 5, 256)         884992    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 2, 2, 256)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 2, 2, 256)         1024      \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 4096)              4198400   \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 4096)              16384     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 4096)              16384     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1000)              4097000   \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 1000)              0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 1000)              4000      \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1000)              1001000   \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 1000)              0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 1000)              4000      \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 120)               120120    \n",
            "=================================================================\n",
            "Total params: 29,988,232\n",
            "Trainable params: 29,966,632\n",
            "Non-trainable params: 21,600\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_F9FfyFSQl_5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8eed30ca-fa64-43b4-920d-96773ba7f326"
      },
      "source": [
        "from tensorflow.keras import layers\r\n",
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\r\n",
        "\r\n",
        "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\r\n",
        "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\r\n",
        "normalization_layer = layers.experimental.preprocessing.Rescaling(1./255)\r\n",
        "normalized_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\r\n",
        "epochs=40\r\n",
        "history = model.fit(\r\n",
        "  train_ds,\r\n",
        "  validation_data=val_ds,\r\n",
        "  epochs=epochs\r\n",
        ")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "491/491 [==============================] - 23s 48ms/step - loss: 5.3053 - accuracy: 0.0147 - val_loss: 5.3754 - val_accuracy: 0.0201\n",
            "Epoch 2/40\n",
            "491/491 [==============================] - 14s 29ms/step - loss: 4.9710 - accuracy: 0.0230 - val_loss: 5.4958 - val_accuracy: 0.0235\n",
            "Epoch 3/40\n",
            "491/491 [==============================] - 14s 29ms/step - loss: 4.8107 - accuracy: 0.0235 - val_loss: 4.7242 - val_accuracy: 0.0311\n",
            "Epoch 4/40\n",
            "491/491 [==============================] - 14s 29ms/step - loss: 4.6700 - accuracy: 0.0291 - val_loss: 4.9180 - val_accuracy: 0.0352\n",
            "Epoch 5/40\n",
            "491/491 [==============================] - 14s 29ms/step - loss: 4.5435 - accuracy: 0.0356 - val_loss: 5.0618 - val_accuracy: 0.0441\n",
            "Epoch 6/40\n",
            "491/491 [==============================] - 14s 28ms/step - loss: 4.4503 - accuracy: 0.0379 - val_loss: 5.0081 - val_accuracy: 0.0487\n",
            "Epoch 7/40\n",
            "491/491 [==============================] - 14s 28ms/step - loss: 4.3554 - accuracy: 0.0422 - val_loss: 4.4869 - val_accuracy: 0.0548\n",
            "Epoch 8/40\n",
            "491/491 [==============================] - 14s 29ms/step - loss: 4.3193 - accuracy: 0.0413 - val_loss: 4.8885 - val_accuracy: 0.0385\n",
            "Epoch 9/40\n",
            "491/491 [==============================] - 14s 29ms/step - loss: 4.2395 - accuracy: 0.0494 - val_loss: 4.5751 - val_accuracy: 0.0584\n",
            "Epoch 10/40\n",
            "491/491 [==============================] - 14s 29ms/step - loss: 4.1846 - accuracy: 0.0560 - val_loss: 4.7620 - val_accuracy: 0.0495\n",
            "Epoch 11/40\n",
            "491/491 [==============================] - 14s 28ms/step - loss: 4.1221 - accuracy: 0.0611 - val_loss: 4.7222 - val_accuracy: 0.0314\n",
            "Epoch 12/40\n",
            "491/491 [==============================] - 14s 28ms/step - loss: 4.0773 - accuracy: 0.0613 - val_loss: 4.0813 - val_accuracy: 0.0747\n",
            "Epoch 13/40\n",
            "491/491 [==============================] - 14s 29ms/step - loss: 4.0379 - accuracy: 0.0705 - val_loss: 4.4467 - val_accuracy: 0.0507\n",
            "Epoch 14/40\n",
            "491/491 [==============================] - 14s 29ms/step - loss: 4.0032 - accuracy: 0.0695 - val_loss: 4.3121 - val_accuracy: 0.0742\n",
            "Epoch 15/40\n",
            "491/491 [==============================] - 14s 29ms/step - loss: 3.9402 - accuracy: 0.0783 - val_loss: 4.3939 - val_accuracy: 0.0655\n",
            "Epoch 16/40\n",
            "491/491 [==============================] - 14s 29ms/step - loss: 3.9062 - accuracy: 0.0821 - val_loss: 4.0036 - val_accuracy: 0.0882\n",
            "Epoch 17/40\n",
            "491/491 [==============================] - 14s 29ms/step - loss: 3.8525 - accuracy: 0.0862 - val_loss: 4.2445 - val_accuracy: 0.0660\n",
            "Epoch 18/40\n",
            "491/491 [==============================] - 14s 29ms/step - loss: 3.8072 - accuracy: 0.0909 - val_loss: 4.0153 - val_accuracy: 0.0984\n",
            "Epoch 19/40\n",
            "491/491 [==============================] - 14s 28ms/step - loss: 3.7585 - accuracy: 0.1037 - val_loss: 4.2226 - val_accuracy: 0.0650\n",
            "Epoch 20/40\n",
            "491/491 [==============================] - 14s 29ms/step - loss: 3.7042 - accuracy: 0.1098 - val_loss: 4.1126 - val_accuracy: 0.0831\n",
            "Epoch 21/40\n",
            "491/491 [==============================] - 14s 29ms/step - loss: 3.6528 - accuracy: 0.1159 - val_loss: 3.9707 - val_accuracy: 0.1071\n",
            "Epoch 22/40\n",
            "491/491 [==============================] - 14s 29ms/step - loss: 3.5904 - accuracy: 0.1214 - val_loss: 4.1234 - val_accuracy: 0.0846\n",
            "Epoch 23/40\n",
            "491/491 [==============================] - 14s 29ms/step - loss: 3.5210 - accuracy: 0.1388 - val_loss: 4.1214 - val_accuracy: 0.0821\n",
            "Epoch 24/40\n",
            "491/491 [==============================] - 14s 29ms/step - loss: 3.4814 - accuracy: 0.1418 - val_loss: 4.1805 - val_accuracy: 0.1078\n",
            "Epoch 25/40\n",
            "491/491 [==============================] - 14s 28ms/step - loss: 3.4195 - accuracy: 0.1518 - val_loss: 4.0433 - val_accuracy: 0.0897\n",
            "Epoch 26/40\n",
            "491/491 [==============================] - 14s 29ms/step - loss: 3.3587 - accuracy: 0.1632 - val_loss: 3.9184 - val_accuracy: 0.1088\n",
            "Epoch 27/40\n",
            "491/491 [==============================] - 14s 28ms/step - loss: 3.3030 - accuracy: 0.1775 - val_loss: 3.9460 - val_accuracy: 0.1389\n",
            "Epoch 28/40\n",
            "491/491 [==============================] - 14s 28ms/step - loss: 3.2486 - accuracy: 0.1833 - val_loss: 3.7255 - val_accuracy: 0.1346\n",
            "Epoch 29/40\n",
            "491/491 [==============================] - 14s 28ms/step - loss: 3.1826 - accuracy: 0.1971 - val_loss: 4.1643 - val_accuracy: 0.1071\n",
            "Epoch 30/40\n",
            "491/491 [==============================] - 14s 28ms/step - loss: 3.1418 - accuracy: 0.2001 - val_loss: 3.6473 - val_accuracy: 0.1450\n",
            "Epoch 31/40\n",
            "491/491 [==============================] - 14s 28ms/step - loss: 3.0963 - accuracy: 0.2137 - val_loss: 3.6975 - val_accuracy: 0.1433\n",
            "Epoch 32/40\n",
            "491/491 [==============================] - 14s 28ms/step - loss: 3.0174 - accuracy: 0.2234 - val_loss: 4.6654 - val_accuracy: 0.0892\n",
            "Epoch 33/40\n",
            "491/491 [==============================] - 14s 28ms/step - loss: 2.9660 - accuracy: 0.2394 - val_loss: 3.7250 - val_accuracy: 0.1427\n",
            "Epoch 34/40\n",
            "491/491 [==============================] - 14s 28ms/step - loss: 2.9005 - accuracy: 0.2488 - val_loss: 3.8635 - val_accuracy: 0.1351\n",
            "Epoch 35/40\n",
            "491/491 [==============================] - 14s 28ms/step - loss: 2.8599 - accuracy: 0.2570 - val_loss: 3.7926 - val_accuracy: 0.1639\n",
            "Epoch 36/40\n",
            "491/491 [==============================] - 14s 28ms/step - loss: 2.8055 - accuracy: 0.2695 - val_loss: 3.6800 - val_accuracy: 0.1601\n",
            "Epoch 37/40\n",
            "491/491 [==============================] - 14s 28ms/step - loss: 2.7352 - accuracy: 0.2825 - val_loss: 3.6559 - val_accuracy: 0.1598\n",
            "Epoch 38/40\n",
            "491/491 [==============================] - 14s 28ms/step - loss: 2.6827 - accuracy: 0.2878 - val_loss: 3.6274 - val_accuracy: 0.1713\n",
            "Epoch 39/40\n",
            "491/491 [==============================] - 14s 28ms/step - loss: 2.6219 - accuracy: 0.3000 - val_loss: 3.6052 - val_accuracy: 0.1787\n",
            "Epoch 40/40\n",
            "491/491 [==============================] - 14s 28ms/step - loss: 2.5573 - accuracy: 0.3157 - val_loss: 3.7858 - val_accuracy: 0.1542\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQtZNftfaL9g"
      },
      "source": [
        "# save model\r\n",
        "model.save(\"my_h5_model.h5\")\r\n",
        "model.save_weights(\"weight_model.h5\")"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQOuupA14OML",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b729146-bba3-45c3-c5d3-a353556a9207"
      },
      "source": [
        "results = model.evaluate(test_ds)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "31/31 [==============================] - 2s 57ms/step - loss: 3.7657 - accuracy: 0.2289\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1xxd5vxkH48j",
        "outputId": "f4ff614b-1a85-483a-df6a-fc82bee98f9b"
      },
      "source": [
        "# Xception with ready weights! ########\r\n",
        "\r\n",
        "# load dataset again! #######\r\n",
        "\r\n",
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\r\n",
        "train_path = Path(\"./dataset/train\")\r\n",
        "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\r\n",
        "    train_path,\r\n",
        "    validation_split=0.2,\r\n",
        "    seed=123,\r\n",
        "    shuffle=True,\r\n",
        "    image_size=(227, 227),\r\n",
        "    batch_size=32,\r\n",
        "    label_mode='categorical',\r\n",
        "    subset='training')\r\n",
        "\r\n",
        "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\r\n",
        "    train_path,\r\n",
        "    image_size=(227, 227),\r\n",
        "    batch_size=32,\r\n",
        "    seed=123,\r\n",
        "    shuffle=True,\r\n",
        "    validation_split=0.2,\r\n",
        "    label_mode='categorical',\r\n",
        "    subset='validation')\r\n",
        " \r\n",
        "test_path = Path(\"./dataset/test\")\r\n",
        "test_ds = keras.preprocessing.image_dataset_from_directory(test_path,\r\n",
        "                                                                seed=28,\r\n",
        "                                                                batch_size=batch_size,\r\n",
        "                                                                image_size=(227, 227),\r\n",
        "                                                                label_mode='categorical')\r\n",
        "\r\n",
        "def preprocess(data, label):\r\n",
        "    data_preprocessed = keras.applications.xception.preprocess_input(data)\r\n",
        "    return data_preprocessed, label\r\n",
        "\r\n",
        "\r\n",
        "train_ds = train_ds.map(preprocess)\r\n",
        "val_ds = val_ds.map(preprocess)\r\n",
        "train_ds = train_ds.cache().shuffle(21000).prefetch(buffer_size=AUTOTUNE)\r\n",
        "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 19619 files belonging to 120 classes.\n",
            "Using 15696 files for training.\n",
            "Found 19619 files belonging to 120 classes.\n",
            "Using 3923 files for validation.\n",
            "Found 961 files belonging to 120 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ATQMDY1Mdeq"
      },
      "source": [
        "from keras.models import Model\r\n",
        "from keras import layers\r\n",
        "from keras.layers import Dense, Input, BatchNormalization, Activation\r\n",
        "from keras.layers import Conv2D, SeparableConv2D, MaxPooling2D, GlobalAveragePooling2D, GlobalMaxPooling2D\r\n",
        "from keras.utils.data_utils import get_file\r\n",
        "\r\n",
        "def create_base_model():\r\n",
        "  url = 'https://github.com/fchollet/deep-learning-models/releases/download/v0.4/xception_weights_tf_dim_ordering_tf_kernels_notop.h5'\r\n",
        "  img_input =  keras.Input((227, 227, 3))\r\n",
        "\r\n",
        "  # Block 1\r\n",
        "  x = Conv2D(32,(3,3),strides=(2,2),use_bias=False)(img_input)\r\n",
        "  x = BatchNormalization()(x)\r\n",
        "  x = Activation('relu')(x)\r\n",
        "  x = Conv2D(64, (3, 3), use_bias=False)(x)\r\n",
        "  x = BatchNormalization()(x)\r\n",
        "  x = Activation('relu')(x)\r\n",
        "  residual = Conv2D(128, (1, 1), strides=(2, 2), padding='same', use_bias=False)(x)\r\n",
        "  residual = BatchNormalization()(residual)\r\n",
        "\r\n",
        "  # Block 2\r\n",
        "  x = SeparableConv2D(128, (3, 3), padding='same', use_bias=False)(x)\r\n",
        "  x = BatchNormalization()(x)\r\n",
        "  x = Activation('relu')(x)\r\n",
        "  x = SeparableConv2D(128, (3, 3), padding='same', use_bias=False)(x)\r\n",
        "  x = BatchNormalization()(x)\r\n",
        "\r\n",
        "  # Block 2 Pool\r\n",
        "  x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\r\n",
        "  x = layers.add([x, residual])\r\n",
        "  residual = Conv2D(256, (1, 1), strides=(2, 2), padding='same', use_bias=False)(x)\r\n",
        "  residual = BatchNormalization()(residual)\r\n",
        "\r\n",
        "  # Block 3\r\n",
        "  x = Activation('relu')(x)\r\n",
        "  x = SeparableConv2D(256, (3, 3), padding='same', use_bias=False)(x)\r\n",
        "  x = BatchNormalization()(x)\r\n",
        "  x = Activation('relu')(x)\r\n",
        "  x = SeparableConv2D(256, (3, 3), padding='same', use_bias=False)(x)\r\n",
        "  x = BatchNormalization()(x)\r\n",
        "\r\n",
        "  # Block 3 Pool\r\n",
        "  x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\r\n",
        "  x = layers.add([x, residual])\r\n",
        "  residual = Conv2D(728, (1, 1), strides=(2, 2), padding='same', use_bias=False)(x)\r\n",
        "  residual = BatchNormalization()(residual)\r\n",
        "\r\n",
        "  # Block 4\r\n",
        "  x = Activation('relu')(x)\r\n",
        "  x = SeparableConv2D(728, (3, 3), padding='same', use_bias=False)(x)\r\n",
        "  x = BatchNormalization()(x)\r\n",
        "  x = Activation('relu')(x)\r\n",
        "  x = SeparableConv2D(728, (3, 3), padding='same', use_bias=False)(x)\r\n",
        "  x = BatchNormalization()(x)\r\n",
        "  x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\r\n",
        "  x = layers.add([x, residual])\r\n",
        "\r\n",
        "  # Block 5 -> 12\r\n",
        "  for i in range(8):\r\n",
        "    residual = x\r\n",
        "    x = Activation('relu')(x)\r\n",
        "    x = SeparableConv2D(728, (3, 3), padding='same', use_bias=False)(x)\r\n",
        "    x = BatchNormalization()(x)\r\n",
        "    x = Activation('relu')(x)\r\n",
        "    x = SeparableConv2D(728, (3, 3), padding='same', use_bias=False)(x)\r\n",
        "    x = BatchNormalization()(x)\r\n",
        "    x = Activation('relu')(x)\r\n",
        "    x = SeparableConv2D(728, (3, 3), padding='same', use_bias=False)(x)\r\n",
        "    x = BatchNormalization()(x)\r\n",
        "    x = layers.add([x, residual])\r\n",
        "\r\n",
        "  residual = Conv2D(1024, (1, 1), strides=(2, 2), padding='same', use_bias=False)(x)\r\n",
        "  residual = BatchNormalization()(residual)\r\n",
        "\r\n",
        "  # Block 13\r\n",
        "  x = Activation('relu')(x)\r\n",
        "  x = SeparableConv2D(728, (3, 3), padding='same', use_bias=False)(x)\r\n",
        "  x = BatchNormalization()(x)\r\n",
        "  x = Activation('relu')(x)\r\n",
        "  x = SeparableConv2D(1024, (3, 3), padding='same', use_bias=False)(x)\r\n",
        "  x = BatchNormalization()(x)\r\n",
        "\r\n",
        "  # Block 13 Pool\r\n",
        "  x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\r\n",
        "  x = layers.add([x, residual])\r\n",
        "\r\n",
        "  # Block 14\r\n",
        "  x = SeparableConv2D(1536, (3, 3), padding='same', use_bias=False)(x)\r\n",
        "  x = BatchNormalization()(x)\r\n",
        "  x = Activation('relu')(x)\r\n",
        "\r\n",
        "  # Block 14 part 2\r\n",
        "  x = SeparableConv2D(2048, (3, 3), padding='same', use_bias=False)(x)\r\n",
        "  x = BatchNormalization()(x)\r\n",
        "  x = Activation('relu')(x)\r\n",
        "\r\n",
        "  model = Model(img_input, x, name='xception')\r\n",
        "  weights = get_file('xception_weights_tf_dim_ordering_tf_kernels_notop.h5', url, cache_subdir='models')\r\n",
        "  model.load_weights(weights)\r\n",
        "  \r\n",
        "  return model"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aKJnxCiDGKey"
      },
      "source": [
        "from keras.utils.vis_utils import plot_model\r\n",
        "\r\n",
        "def xception():\r\n",
        "    base_model = create_base_model()\r\n",
        "    base_model.trainable = False\r\n",
        "    x = base_model.output\r\n",
        "    x = GlobalAveragePooling2D()(x)\r\n",
        "    x = Dropout(0.2)(x)\r\n",
        "    predictions = Dense(120, activation='softmax')(x)\r\n",
        "\r\n",
        "    model = Model(inputs=base_model.input, outputs=predictions)\r\n",
        "\r\n",
        "    for layer in base_model.layers:\r\n",
        "        layer.trainable = False\r\n",
        "\r\n",
        "    model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\r\n",
        "    # model.summary()\r\n",
        "    plot_model(model, to_file='xception_model.png', show_shapes=True, show_layer_names=True)\r\n",
        "    for i, layer in enumerate(model.layers):\r\n",
        "        if i < 81:\r\n",
        "            layer.trainable = False\r\n",
        "        else:\r\n",
        "            layer.trainable = True\r\n",
        "\r\n",
        "    history = model.fit(train_ds, batch_size=32, epochs=10, validation_data=val_ds,verbose=1)\r\n",
        "    return model"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eLzj_Joe1UEH",
        "outputId": "82dad248-1c50-4952-9281-34eb080d1be3"
      },
      "source": [
        "model = xception()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "491/491 [==============================] - 48s 98ms/step - loss: 0.8582 - accuracy: 0.7753 - val_loss: 0.5841 - val_accuracy: 0.8249\n",
            "Epoch 2/10\n",
            "491/491 [==============================] - 47s 96ms/step - loss: 0.5047 - accuracy: 0.8510 - val_loss: 0.6294 - val_accuracy: 0.8251\n",
            "Epoch 3/10\n",
            "491/491 [==============================] - 47s 96ms/step - loss: 0.4757 - accuracy: 0.8651 - val_loss: 0.6525 - val_accuracy: 0.8292\n",
            "Epoch 4/10\n",
            "491/491 [==============================] - 48s 97ms/step - loss: 0.4484 - accuracy: 0.8744 - val_loss: 0.6904 - val_accuracy: 0.8267\n",
            "Epoch 5/10\n",
            "491/491 [==============================] - 47s 96ms/step - loss: 0.4305 - accuracy: 0.8829 - val_loss: 0.7144 - val_accuracy: 0.8338\n",
            "Epoch 6/10\n",
            "491/491 [==============================] - 47s 96ms/step - loss: 0.4108 - accuracy: 0.8902 - val_loss: 0.7384 - val_accuracy: 0.8318\n",
            "Epoch 7/10\n",
            "491/491 [==============================] - 47s 96ms/step - loss: 0.4000 - accuracy: 0.8948 - val_loss: 0.7492 - val_accuracy: 0.8320\n",
            "Epoch 8/10\n",
            "491/491 [==============================] - 47s 96ms/step - loss: 0.3883 - accuracy: 0.8986 - val_loss: 0.7785 - val_accuracy: 0.8323\n",
            "Epoch 9/10\n",
            "491/491 [==============================] - 47s 96ms/step - loss: 0.3702 - accuracy: 0.9038 - val_loss: 0.8025 - val_accuracy: 0.8318\n",
            "Epoch 10/10\n",
            "491/491 [==============================] - 47s 96ms/step - loss: 0.3601 - accuracy: 0.9078 - val_loss: 0.8263 - val_accuracy: 0.8318\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6-Iyu0faQfMQ",
        "outputId": "7dec7e75-3837-4b44-b895-f38fcc695681"
      },
      "source": [
        "# save model\r\n",
        "model.save(\"my_h5_model2.h5\")\r\n",
        "model.save_weights(\"weight_model2.h5\")\r\n",
        "test_ds = test_ds.map(preprocess)\r\n",
        "results = model.evaluate(test_ds)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "31/31 [==============================] - 4s 126ms/step - loss: 0.7473 - accuracy: 0.8377\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RiwOf8jmTrhk"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}